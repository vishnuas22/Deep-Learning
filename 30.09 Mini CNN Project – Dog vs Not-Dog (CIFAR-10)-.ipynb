{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "\n",
    "import torch.nn as nn \n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from  torchvision import datasets, transforms\n",
    "\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform: Convert to tensor and normalize (grayscale optional)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "\n",
    "    transforms.ToTensor(),\n",
    "\n",
    "    transforms.Normalize((0.5),(0.5))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Full CIFAR-10\n",
    "\n",
    "train_set = torchvision.datasets.CIFAR10(root='.data', train=True, download='True',transform=transform)\n",
    "\n",
    "test_set = torchvision.datasets.CIFAR10(root='.data', train=False, download='True',transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label map\n",
    "\n",
    "def filter_dataset(dataset):\n",
    "\n",
    "    idx = [i for i, (_, label)in enumerate (dataset) if label == 5 or label !=5]\n",
    "\n",
    "    images = [dataset[i][0] for i in idx]\n",
    "\n",
    "    labels = [1 if dataset[i][1]==5 else 0 for i in idx] # 1 = dog, 0 = not-dog\n",
    "\n",
    "    return list(zip(images,labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filtered = filter_dataset(train_data)\n",
    "\n",
    "test_filtered = filter_dataset(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Training Samples: 50000\n",
      "Filtered Testing Samples: 10000\n"
     ]
    }
   ],
   "source": [
    "# Wrap in DataLoader\n",
    "\n",
    "train_loader = DataLoader(train_filtered, batch_size=64, shuffle=True)\n",
    "\n",
    "test_loader = DataLoader(test_filtered, batch_size=64, shuffle=False)\n",
    "\n",
    "print(f'Filtered Training Samples: {len(train_filtered)}')\n",
    "\n",
    "print(f'Filtered Testing Samples: {len(test_filtered)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conv(1 → 8) → ReLU → MaxPool\n",
    "Conv(8 → 16) → ReLU → MaxPool\n",
    "Flatten → FC(16×6×6 → 32) → ReLU → FC(32 → 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DogNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(DogNet,self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 8 , kernel_size=3, padding=1) # [B, 1, 32, 32] -> [B, 8, 32, 32]\n",
    "\n",
    "        self.pool = nn.MaxPool2d(2,2)  # -> [B, 8, 16, 16]\n",
    "\n",
    "        self.conv2 = nn.Conv2d(8,16 , kernel_size=3, padding=1)  # -> [B, 16, 16, 16] → [B, 16, 8, 8]\n",
    "\n",
    "\n",
    "        self.fc1 = nn.Linear(16 * 8 * 8, 32)\n",
    "\n",
    "        self.fc2 = nn.Linear(32, 2)  # Output: Dog or Not-Dog\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "\n",
    "        x = self.pool(F.relu(self.conv1(x))) # Conv1 + ReLU + Pool\n",
    "\n",
    "        x = self.pool(F.relu(self.conv2(x)))  # Conv2 + ReLU + Pool\n",
    "\n",
    "        x = x.view(-1, 16 * 8 * 8)   # Flatten\n",
    "\n",
    "        x = F.relu(self.fc1(x)) # FC1 + ReLU\n",
    "\n",
    "        x = self.fc2(x)         # Final FC\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MPS (Metal GPU on Mac)\n",
      "DogNet(\n",
      "  (conv1): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (fc1): Linear(in_features=1024, out_features=32, bias=True)\n",
      "  (fc2): Linear(in_features=32, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define your model\n",
    "\n",
    "model = DogNet()\n",
    "\n",
    "# Device setup for Mac M1\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "\n",
    "    device = torch.device(\"mps\")\n",
    "\n",
    "    print(\"Using MPS (Metal GPU on Mac)\")\n",
    "\n",
    "else:\n",
    "\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "    print(\"Using CPU\")\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "print(model)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "masterxdl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
