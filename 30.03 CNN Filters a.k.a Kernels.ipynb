{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Think of filters as feature detectors. Each filter scans over the image and \"activates\" when it detects a specific type of pattern.\n",
    "\n",
    "ðŸ§  Analogy:\n",
    "\n",
    "A filter is like a mini detective magnifying glass that looks for certain clues â€” edges, textures, corners, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How It Works\n",
    "\n",
    "A filter is a small matrix (e.g., 3Ã—3 or 5Ã—5) with learnable weights. During convolution:\n",
    "\n",
    "The filter slides (or convolves) over the input image.\n",
    "\n",
    "At each location, it performs an element-wise multiplication with the image patch.\n",
    "\n",
    "The results are summed into a single number â€” that's your activation at that point.\n",
    "\n",
    "The output is a feature map (or activation map) showing how strongly the pattern appears across the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a grayscale image\n",
    "\n",
    "Define 3 custom filters: edge detector, sharpen, and blur\n",
    "\n",
    "Apply them using torch.nn.functional.conv2d to show how filters transform an image\n",
    "\n",
    "Then we'll show what learned filters might look like in a trained CNN.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'https://upload.wikimedia.org/wikipedia/commons/7/7d/Dog_face.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load and preprocess grayscale image\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhttps://upload.wikimedia.org/wikipedia/commons/7/7d/Dog_face.png\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m transform \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mCompose([\n\u001b[1;32m      6\u001b[0m \n\u001b[1;32m      7\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mToTensor(),\n\u001b[1;32m      8\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mResize(\u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m128\u001b[39m)\n\u001b[1;32m      9\u001b[0m ])\n\u001b[1;32m     11\u001b[0m img_tensor \u001b[38;5;241m=\u001b[39m transform(img)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;66;03m# [1, 1, H, W]\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/masterxdl/lib/python3.9/site-packages/PIL/Image.py:3465\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3462\u001b[0m     filename \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mfspath(fp)\n\u001b[1;32m   3464\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename:\n\u001b[0;32m-> 3465\u001b[0m     fp \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3466\u001b[0m     exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   3467\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'https://upload.wikimedia.org/wikipedia/commons/7/7d/Dog_face.png'"
     ]
    }
   ],
   "source": [
    "# Load and preprocess grayscale image\n",
    "\n",
    "img = Image.open(\"https://upload.wikimedia.org/wikipedia/commons/7/7d/Dog_face.png\").convert('L')\n",
    "\n",
    "transform = transforms.Compose([\n",
    "\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize(128, 128)\n",
    "])\n",
    "\n",
    "img_tensor = transform(img).unsqueeze(0) # [1, 1, H, W]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define filters: edge detection, sharpen, blur\n",
    "\n",
    "edge_filter = torch.tensor([[-1, -1, -1],\n",
    "                            [-1, 8, -1],\n",
    "                            [-1, -1, -1]], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sharpen_filter = torch.tensor([[0, -1, 0],\n",
    "                            [-1, 5, -1],\n",
    "                            [0, -1, 0]], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blur_filter = torch.tensor([[1, 1, 1],\n",
    "                            [1, 1, 1],\n",
    "                            [1, 1, 1]], dtype=torch.float32)/ 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = torch.stack([edge_filter, sharpen_filter, blur_filter]).unsqueeze(1) # [3,1,3,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply filters using conv2d\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    filtered_imgs = F.conv2d(img_tensor, filters, padding=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "\n",
    "titles = ['Edge detection', 'Sharpen', 'Blur']\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "\n",
    "for i in range(3):\n",
    "\n",
    "    plt.subplot(1, 3, i+1)\n",
    "\n",
    "    plt.imshow(filtered_imgs[0, i], cmap='gray')\n",
    "\n",
    "    plt.title(titles[i])\n",
    "\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "masterxdl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
