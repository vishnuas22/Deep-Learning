{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29fc96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "# Dummy toy dataset\n",
    "tokens = [\"i\", \"like\", \"deep\", \"learning\", \"and\", \"nlp\", \"is\", \"fun\"]\n",
    "word_to_idx = {w: i for i, w in enumerate(tokens)}\n",
    "idx_to_word = {i: w for w, i in word_to_idx.items()}\n",
    "\n",
    "data = [\n",
    "    [\"i\", \"like\", \"deep\", \"learning\"],\n",
    "    [\"deep\", \"learning\", \"and\", \"nlp\"],\n",
    "    [\"nlp\", \"is\", \"fun\", \"i\"]\n",
    "]\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for seq in data:\n",
    "    X.append([word_to_idx[w] for w in seq[:3]])\n",
    "    y.append(word_to_idx[seq[3]])\n",
    "\n",
    "X = torch.tensor(X)\n",
    "y = torch.tensor(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c177646",
   "metadata": {},
   "source": [
    "Step 2: GRU Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5f9ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUModel(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_size)\n",
    "        self.gru = nn.GRU(emb_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        out, _ = self.gru(x)\n",
    "        return self.fc(out[:, -1, :])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f42c18",
   "metadata": {},
   "source": [
    "Step 3: LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed0e8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_size)\n",
    "        self.lstm = nn.LSTM(emb_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        out, _ = self.lstm(x)\n",
    "        return self.fc(out[:, -1, :])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d0772b",
   "metadata": {},
   "source": [
    " Step 4: Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c0cc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, X, y, epochs=300):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        out = model(X)\n",
    "        loss = criterion(out, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if epoch % 100 == 0:\n",
    "            print(f\"Epoch {epoch}/{epochs}, Loss: {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468e8081",
   "metadata": {},
   "source": [
    "Step 5: Run Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b7c5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(tokens)\n",
    "emb_size = 10\n",
    "hidden_size = 16\n",
    "\n",
    "print(\"\\n--- Training GRU ---\")\n",
    "gru_model = GRUModel(vocab_size, emb_size, hidden_size)\n",
    "train(gru_model, X, y)\n",
    "\n",
    "print(\"\\n--- Training LSTM ---\")\n",
    "lstm_model = LSTMModel(vocab_size, emb_size, hidden_size)\n",
    "train(lstm_model, X, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c554b7",
   "metadata": {},
   "source": [
    "Final: Compare Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bff512",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next_word(model, seed_words):\n",
    "    model.eval()\n",
    "    input_seq = torch.tensor([[word_to_idx[w] for w in seed_words]])\n",
    "    with torch.no_grad():\n",
    "        out = model(input_seq)\n",
    "        pred_idx = torch.argmax(out, dim=1).item()\n",
    "    return idx_to_word[pred_idx]\n",
    "\n",
    "print(\"\\nGRU Prediction:\", predict_next_word(gru_model, [\"i\", \"like\", \"deep\"]))\n",
    "print(\"LSTM Prediction:\", predict_next_word(lstm_model, [\"i\", \"like\", \"deep\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49bb6b5",
   "metadata": {},
   "source": [
    "GRU converges faster (fewer parameters)\n",
    "LSTM may perform better on longer contexts\n",
    "For small tasks, both work similarly"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
