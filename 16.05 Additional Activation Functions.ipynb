{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1Ô∏è‚É£ Exponential Linear Unit (ELU)\n",
    "\n",
    "‚úÖ Why is it useful?\n",
    "Unlike ReLU, ELU allows small negative values for \n",
    "\n",
    "x‚â§0, avoiding the \"dying ReLU\" problem.\n",
    "\n",
    "Smooth gradient helps in better training compared to Leaky ReLU.\n",
    "\n",
    "‚úÖ Downsides?\n",
    "\n",
    "Computationally expensive because of the exponential term.\n",
    "More complex than ReLU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2Ô∏è‚É£ Swish (Self-Gated Activation)\n",
    "‚úÖ Formula:\n",
    "\n",
    "Swish(x)=x‚ãÖsigmoid(x)\n",
    "\n",
    "Swish(x)=x‚ãÖ \n",
    "1+e \n",
    "‚àíx\n",
    " \n",
    "1\n",
    " \n",
    "‚úÖ Why is it useful?\n",
    "\n",
    "Unlike ReLU, it is smooth and non-monotonic, meaning it can let small negative values pass instead of zeroing them out.\n",
    "\n",
    "Google found that Swish outperforms ReLU in deep networks.\n",
    "\n",
    "Helps prevent dead neurons like ELU.\n",
    "\n",
    "‚úÖ Downsides?\n",
    "\n",
    "Slightly more computationally expensive than ReLU.\n",
    "\n",
    "Works best in deeper networks rather than simple ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3Ô∏è‚É£ Softmax (for Multi-Class Classification)\n",
    "\n",
    "It converts logits (raw output scores) into probabilities that sum to 1, making it useful for multi-class classification.\n",
    "\n",
    "‚úÖ Why is it useful?\n",
    "\n",
    "Converts arbitrary real values into probability distributions.\n",
    "Ensures the sum of all outputs is 1, making it easy to interpret as probabilities.\n",
    "Used in classification tasks like image recognition.\n",
    "\n",
    "‚úÖ Downsides?\n",
    "\n",
    "Susceptible to large numerical values (softmax can cause exploding gradients).\n",
    "\n",
    "Can amplify small differences in inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input tensor\n",
    "\n",
    "x = torch.tensor([-1.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activation functions\n",
    "\n",
    "elu = F.elu(x, alpha=1.0)\n",
    "\n",
    "swish = x * torch.sigmoid(x)\n",
    "\n",
    "softmax = F.softmax(torch.tensor([2.0, 1.0, 0.1]), dim=0) # Example input for multi-class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELU : -0.7768698334693909\n",
      "SWISH : -0.2736383080482483\n",
      "Softmax ( Example inputs ([2.0,1.0, 0.1]) : [0.6590011715888977, 0.24243298172950745, 0.09856589138507843]\n"
     ]
    }
   ],
   "source": [
    "# Print results\n",
    "\n",
    "print(f'ELU : {elu.item()}')\n",
    "\n",
    "print(f'SWISH : {swish.item()}')\n",
    "\n",
    "print(f'Softmax ( Example inputs ([2.0,1.0, 0.1]) : {softmax.tolist()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëâ Key Takeaways\n",
    "\n",
    "Use ReLU for most hidden layers (fast & simple).\n",
    "\n",
    "Use Leaky ReLU/ELU if you see dead neurons with ReLU.\n",
    "\n",
    "Use Swish if you want better optimization at a small computational cost.\n",
    "\n",
    "Use Sigmoid/Tanh for specific cases like binary classification or zero-centered activations.\n",
    "\n",
    "Use Softmax in the last layer of multi-class classification tasks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "masterxdl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
